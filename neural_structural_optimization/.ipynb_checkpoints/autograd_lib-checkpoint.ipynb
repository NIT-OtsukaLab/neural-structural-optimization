{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lint as python3\n",
    "Copyright 2019 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pylint: disable=missing-docstring\n",
    "pylint: disable=unused-argument\n",
    "pylint: disable=g-import-not-at-top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.core\n",
    "import autograd.extend\n",
    "import autograd.numpy as anp\n",
    "from neural_structural_optimization import caching\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.ndimage\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "try:\n",
    "  import sksparse.cholmod\n",
    "  HAS_CHOLMOD = True\n",
    "except ImportError:\n",
    "  warnings.warn(\n",
    "      'sksparse.cholmod not installed. Falling back to SciPy/SuperLU, but '\n",
    "      'simulations will be about twice as slow.')\n",
    "  HAS_CHOLMOD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal utilities\n",
    "def _grad_undefined(_, *args):\n",
    "  raise TypeError('gradient undefined for this input argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zero_grad(_, *args, **kwargs):\n",
    "  def jvp(grad_ans):\n",
    "    return 0.0 * grad_ans\n",
    "  return jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter\n",
    "@autograd.extend.primitive\n",
    "def gaussian_filter(x, width):\n",
    "  \"\"\"Apply gaussian blur of a given radius.\"\"\"\n",
    "  return scipy.ndimage.gaussian_filter(x, width, mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gaussian_filter_vjp(ans, x, width):\n",
    "  del ans, x  # unused\n",
    "  return lambda g: gaussian_filter(g, width)\n",
    "autograd.extend.defvjp(gaussian_filter, _gaussian_filter_vjp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Cone filter\n",
    "#2021-01-26 K.Taniguchi\n",
    "class NDSparseMatrix:\n",
    "  def __init__(self):\n",
    "    self.elements = {}\n",
    "\n",
    "  def addValue(self, Tuple, value):\n",
    "    self.elements[Tuple] = value\n",
    "\n",
    "  def readValue(self, Tuple):\n",
    "    try:\n",
    "      value = self.elements[Tuple]\n",
    "    except KeyError:\n",
    "      # could also be 0.0 if using floats...\n",
    "      value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _cone_filter_matrix(nelx, nely, nelz, radius, mask):\n",
    "  arange = np.arange(-math.ceil(radius)+1,math.ceil(radius)-1)\n",
    "  [dy, dz, dx] = np.meshgrid(arange, arange, arange)\n",
    "  #dx, dy, dz = np.meshgrid(np.arange(nelx), np.arange(nely), np.arange(nelz), indexing='ij')\n",
    "\n",
    "  weight = np.maximum(0, radius - np.sqrt(np.power(dx,2) + np.power(dy,2) + np.power(dz,2)))\n",
    "  #print(\"len(weigh-list)=\",len(list(weight)),\"for gaussian_filter\")\n",
    "  #print(\"weight.ndim=\",weight.ndim,\"for ndimage.correlate\")\n",
    "  shape = np.ones(shape=(nelz, nely, nelx))\n",
    "  #print(\"shape.ndim=\",shape.ndim)\n",
    "\n",
    "  #hs = scipy.ndimage.gaussian_filter(shape, weight)\n",
    "  #hs = scipy.ndimage.correlate(shape, weight, mode='nearest')\n",
    "  hs = scipy.ndimage.correlate(shape, weight, mode='nearest').transpose()\n",
    "        #hs = scipy.misc.imfilter(shape, weight).transpose() #... RuntimeError: filter weights array has incorrect shape.\n",
    "\n",
    "  #Hs = NDSparseMatrix(hs)\n",
    "  #print(\"Sparse hs=\",Hs)\n",
    "  return hs\n",
    "  #return NDSparseMatrix(hs)\n",
    "  #return scipy.sparse.coo_matrix((data, (i, j)), (nelx * nely,) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#2020-12-15 K.Taniguchi\n",
    "\"\"\"def _cone_filter_matrix(nelx, nely, nelz, radius, mask):\n",
    "  x, y, z = np.meshgrid(np.arange(nelx), np.arange(nely), np.arange(nelz), indexing='ij')\n",
    "\n",
    "  rows = []\n",
    "  cols = []\n",
    "  values = []\n",
    "  r_bound = int(np.ceil(radius))\n",
    "  for dx in range(-r_bound, r_bound+1):\n",
    "    for dy in range(-r_bound, r_bound+1):\n",
    "      for dz in range(-r_bound, r_bound+1):\n",
    "        weight = np.maximum(0, radius - np.sqrt(dx**2 + dy**2 + dz**2))\n",
    "        #weight = np.maximum(0, radius - np.sqrt(dx**2 + dy**2))\n",
    "        row = x + nelx * y\n",
    "        column = x + dx + nelx * (y + dy)\n",
    "        value = np.broadcast_to(weight, x.shape)\n",
    "\n",
    "        # exclude cells beyond the boundary\n",
    "        valid = (\n",
    "            (mask > 0) &\n",
    "            ((x+dx) >= 0) &\n",
    "            ((x+dx) < nelx) &\n",
    "            ((y+dy) >= 0) &\n",
    "            ((y+dy) < nely) &\n",
    "            ((z+dz) >= 0) &\n",
    "            ((z+dz) < nelz)\n",
    "        )\n",
    "        rows.append(row[valid])\n",
    "        cols.append(column[valid])\n",
    "        values.append(value[valid])\n",
    "\n",
    "  data = np.concatenate(values)\n",
    "  i = np.concatenate(rows)\n",
    "  j = np.concatenate(cols)\n",
    "  return scipy.sparse.coo_matrix((data, (i, j)), (nelx * nely * nelz,) * 3)\n",
    "  #return scipy.sparse.coo_matrix((data, (i, j)), (nelx * nely,) * 2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021-01-26 K.Taniguchi\n",
    "@caching.ndarray_safe_lru_cache()\n",
    "def normalized_cone_filter_matrix(nx, ny, nz, radius, mask):\n",
    "  \"\"\"Calculate a sparse matrix appropriate for applying a cone filter.\"\"\"\n",
    "  #raw_filters = _cone_filter_matrix(nx, ny, nz, radius, mask).tocsr()\n",
    "  raw_filters = _cone_filter_matrix(nx, ny, nz, radius, mask)\n",
    "  #weights = 1 / raw_filters.sum(axis=0).squeeze()\n",
    "  #diag_weights = scipy.sparse.spdiags(weights, 0, nx*ny, ny*nz, nz*nx),\n",
    "  #return (diag_weights @ raw_filters).tocsr()\n",
    "  return(raw_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autograd.extend.primitive\n",
    "def cone_filter(inputs, radius, mask=1, transpose=False):\n",
    "  \"\"\"Apply a cone filter of the given radius.\"\"\"\n",
    "  inputs = np.asarray(inputs)\n",
    "  filters = normalized_cone_filter_matrix(*inputs.shape, radius=radius, mask=mask)\n",
    "  if transpose:\n",
    "    filters = filters.T\n",
    "  outputs = filters @ inputs.ravel(order='F')\n",
    "  return outputs.reshape(inputs.shape, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cone_filter_vjp(ans, inputs, radius, mask=1, transpose=False):\n",
    "  del ans, inputs  # unused\n",
    "  return lambda g: cone_filter(g, radius, mask, transpose=not transpose)\n",
    "autograd.extend.defvjp(cone_filter, _cone_filter_vjp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a useful utility for 1D scatter operations\n",
    "def inverse_permutation(indices):\n",
    "  inverse_perm = np.zeros(len(indices), dtype=anp.int64)\n",
    "  inverse_perm[indices] = np.arange(len(indices), dtype=anp.int64)\n",
    "  return inverse_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 1D scatter operation\n",
    "def scatter1d(nonzero_values, nonzero_indices, array_len):\n",
    "  all_indices = np.arange(array_len, dtype=anp.int64)\n",
    "  zero_indices = anp.setdiff1d(all_indices, nonzero_indices, assume_unique=True)\n",
    "  index_map = inverse_permutation(\n",
    "      anp.concatenate([nonzero_indices, zero_indices]))\n",
    "  u_values = anp.concatenate([nonzero_values, anp.zeros(len(zero_indices))])\n",
    "  return u_values[index_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@caching.ndarray_safe_lru_cache(1)\n",
    "def _get_solver(a_entries, a_indices, size, sym_pos):\n",
    "  \"\"\"Get a solver for applying the desired matrix factorization.\"\"\"\n",
    "  # A cache size of one is sufficient to avoid re-computing the factorization in\n",
    "  # the backwawrds pass.\n",
    "  #a = scipy.ndimage.correlate(shape, weight, mode='nearest').transpose()\n",
    "  a = scipy.sparse.coo_matrix((a_entries, a_indices), shape=(size,)*2).tocsc()\n",
    "  if sym_pos and HAS_CHOLMOD:\n",
    "    return sksparse.cholmod.cholesky(a).solve_A\n",
    "  else:\n",
    "    # could also use scikits.umfpack.splu\n",
    "    # should be about twice as slow as the cholesky\n",
    "    return scipy.sparse.linalg.splu(a).solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## Sparse solver\n",
    "@autograd.primitive\n",
    "def solve_coo(a_entries, a_indices, b, sym_pos=False):\n",
    "  \"\"\"Solve a sparse system of linear equations.\n",
    "\n",
    "  Args:\n",
    "    a_entries: numpy array with shape (num_zeros,) giving values for non-zero\n",
    "      matrix entries.\n",
    "    a_indices: numpy array with shape (2, num_zeros) giving x and y indices for\n",
    "      non-zero matrix entries.\n",
    "    b: 1d numpy array specifying the right hand side of the equation.\n",
    "    sym_pos: is the matrix guaranteed to be positive-definite?\n",
    "\n",
    "  Returns:\n",
    "    1d numpy array corresponding to the solution of a*x=b.\n",
    "  \"\"\"\n",
    "\n",
    "  solver = _get_solver(a_entries, a_indices, b.size, sym_pos)\n",
    "  return solver(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "see autograd's np.linalg.solve:\n",
    "https://github.com/HIPS/autograd/blob/96a03f44da43cd7044c61ac945c483955deba957/autograd/numpy/linalg.py#L40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_coo_adjoint(a_entries, a_indices, b, sym_pos=False):\n",
    "  # NOTE: not tested on complex valued inputs.\n",
    "  if sym_pos:\n",
    "    return solve_coo(a_entries, a_indices, b, sym_pos)\n",
    "  else:\n",
    "    return solve_coo(a_entries, a_indices[::-1], b, sym_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_solve_coo_entries(ans, a_entries, a_indices, b, sym_pos=False):\n",
    "  def jvp(grad_ans):\n",
    "    lambda_ = solve_coo_adjoint(a_entries, a_indices, grad_ans, sym_pos)\n",
    "    i, j = a_indices\n",
    "    return -lambda_[i] * ans[j]\n",
    "  return jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_solve_coo_b(ans, a_entries, a_indices, b, sym_pos=False):\n",
    "  def jvp(grad_ans):\n",
    "    return solve_coo_adjoint(a_entries, a_indices, grad_ans, sym_pos)\n",
    "  return jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autograd.extend.defvjp(\n",
    "    solve_coo, grad_solve_coo_entries, _grad_undefined, grad_solve_coo_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autograd.primitive\n",
    "def find_root(\n",
    "    f, x, lower_bound, upper_bound, tolerance=1e-12, max_iterations=64):\n",
    "  # Implicitly solve f(x,y)=0 for y(x) using binary search.\n",
    "  # Assumes that y is a scalar and f(x,y) is monotonic in y.\n",
    "  for _ in range(max_iterations):\n",
    "    y = 0.5 * (lower_bound + upper_bound)\n",
    "    if upper_bound - lower_bound < tolerance:\n",
    "      break\n",
    "    if f(x, y) > 0:\n",
    "      upper_bound = y\n",
    "    else:\n",
    "      lower_bound = y\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_find_root(y, f, x, lower_bound, upper_bound, tolerance=None):\n",
    "  # This uses a special case of the adjoint gradient rule:\n",
    "  # http://www.dolfin-adjoint.org/en/latest/documentation/maths/3-gradients.html#the-adjoint-approach\n",
    "  def jvp(grad_y):\n",
    "    g = lambda x: f(x, y)\n",
    "    h = lambda y: f(x, y)\n",
    "    return -autograd.grad(g)(x) / autograd.grad(h)(y) * grad_y\n",
    "  return jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autograd.extend.defvjp(\n",
    "    find_root, _grad_undefined, grad_find_root,\n",
    "    _zero_grad, _zero_grad, _zero_grad)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
