{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# lint as python3\n",
    "# Copyright 2019 Google LLC.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# pylint: disable=missing-docstring\n",
    "# pylint: disable=invalid-name\n",
    "\n",
    "import autograd\n",
    "import autograd.core\n",
    "import autograd.numpy as np\n",
    "from neural_structural_optimization import topo_api\n",
    "import tensorflow as tf\n",
    "\n",
    "# requires tensorflow 2.0\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "\n",
    "def batched_topo_loss(params, envs):\n",
    "  losses = [env.objective(params[i], volume_contraint=True)\n",
    "            for i, env in enumerate(envs)]\n",
    "  return np.stack(losses)\n",
    "\n",
    "\n",
    "def convert_autograd_to_tensorflow(func):\n",
    "  @tf.custom_gradient\n",
    "  def wrapper(x):\n",
    "    vjp, ans = autograd.core.make_vjp(func, x.numpy())\n",
    "    return ans, vjp\n",
    "  return wrapper\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "  if seed is not None:\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, seed=None, args=None):\n",
    "    super().__init__()\n",
    "    set_random_seed(seed)\n",
    "    self.seed = seed\n",
    "    self.env = topo_api.Environment(args)\n",
    "\n",
    "  def loss(self, logits):\n",
    "    # for our neural network, we use float32, but we use float64 for the physics\n",
    "    # to avoid any chance of overflow.\n",
    "    # add 0.0 to work-around bug in grad of tf.cast on NumPy arrays\n",
    "    logits = 0.0 + tf.cast(logits, tf.float64)\n",
    "    f = lambda x: batched_topo_loss(x, [self.env])\n",
    "    losses = convert_autograd_to_tensorflow(f)(logits)\n",
    "    return tf.reduce_mean(losses)\n",
    "\n",
    "\n",
    "class PixelModel(Model):\n",
    "\n",
    "  def __init__(self, seed=None, args=None):\n",
    "    super().__init__(seed, args)\n",
    "    shape = (self.env.args['nelz'], self.env.args['nely'], self.env.args['nelx'])\t#2020-12-12 K.Taniguchi\n",
    "    z_init = np.broadcast_to(args['volfrac'] * args['mask'], shape)\n",
    "    self.z = tf.Variable(z_init, trainable=True)\n",
    "\n",
    "  def call(self, inputs=None):\n",
    "    return self.z\n",
    "\n",
    "\n",
    "def global_normalization(inputs, epsilon=1e-6):\n",
    "  mean, variance = tf.nn.moments(inputs, axes=list(range(len(inputs.shape))))\n",
    "  net = inputs\n",
    "  net -= mean\n",
    "  net *= tf.math.rsqrt(variance + epsilon)\n",
    "  return net\n",
    "\n",
    "#UpSampling2D→UpSampling3D\t20201214 K.Taniguchi\n",
    "def UpSampling3D(factor):\n",
    "  return layers.UpSampling3D((factor, factor, factor),data_format='channels_last')\n",
    "\n",
    "#Conv2D→Conv3D\t20201214 K.Taniguchi\n",
    "def Conv3D(filters, kernel_size, **kwargs):\n",
    "  return layers.Conv3D(filters, kernel_size, padding='same', **kwargs)\n",
    "\n",
    "\n",
    "class AddOffset(layers.Layer):\n",
    "\n",
    "  def __init__(self, scale=1):\n",
    "    super().__init__()\n",
    "    self.scale = scale\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.bias = self.add_weight(\n",
    "        shape=input_shape, initializer='zeros', trainable=True, name='bias')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.scale * self.bias\n",
    "\n",
    "\n",
    "class CNNModel(Model):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      seed=0,\n",
    "      args=None,\n",
    "      latent_size=128,\n",
    "      dense_channels=32,\n",
    "      resizes=(1, 2, 2, 2, 1),\n",
    "      conv_filters=(128, 64, 32, 16, 1),\n",
    "      offset_scale=10,\n",
    "      kernel_size=(5, 5, 5),\n",
    "      latent_scale=1.0,\n",
    "      dense_init_scale=1.0,\n",
    "      activation=tf.nn.tanh,\n",
    "      conv_initializer=tf.initializers.VarianceScaling,\n",
    "      normalization=global_normalization,\n",
    "  ):\n",
    "    super().__init__(seed, args)\n",
    "\n",
    "    if len(resizes) != len(conv_filters):\n",
    "      raise ValueError('resizes and filters must be same size')\n",
    "\n",
    "    activation = layers.Activation(activation)\n",
    "    \n",
    "    print(\"activation:\",activation)\n",
    "\n",
    "    total_resize = int(np.prod(resizes))\n",
    "    d = self.env.args['nelz'] // total_resize\n",
    "    h = self.env.args['nely'] // total_resize\n",
    "    w = self.env.args['nelx'] // total_resize\n",
    "    \n",
    "    print(\"total_resize:\",total_resize,\", h:\",h,\", w:\",w,\", d:\",d)\n",
    "\n",
    "    net = inputs = layers.Input((latent_size,), batch_size=1)\n",
    "    filters = d * h * w * dense_channels\n",
    "    dense_initializer = tf.initializers.orthogonal(\n",
    "        dense_init_scale * np.sqrt(max(filters / latent_size, 1)))\n",
    "    net = layers.Dense(filters, kernel_initializer=dense_initializer)(net)\n",
    "    net = layers.Reshape([d, h, w, dense_channels])(net)\n",
    "\n",
    "    for resize, filters in zip(resizes, conv_filters):\n",
    "      net = activation(net)\n",
    "      net = UpSampling3D(resize)(net)\n",
    "      net = normalization(net)\n",
    "      net = Conv3D(\n",
    "          filters, kernel_size, kernel_initializer=conv_initializer)(net)\n",
    "      if offset_scale != 0:\n",
    "        net = AddOffset(offset_scale)(net)\n",
    "\n",
    "    outputs = tf.squeeze(net, axis=[-1])\n",
    "\n",
    "    self.core_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    latent_initializer = tf.initializers.RandomNormal(stddev=latent_scale)\n",
    "    self.z = self.add_weight(\n",
    "        shape=inputs.shape, initializer=latent_initializer, name='z')\n",
    "\n",
    "  def call(self, inputs=None):\n",
    "    return self.core_model(self.z)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: {'young': 1, 'young_min': 1e-09, 'poisson': 0.3, 'g': 0, 'volfrac': 0.4, 'xmin': 0.001, 'xmax': 1.0, 'nelx': 192, 'nely': 64, 'nelz': 2, 'mask': 1, 'freedofs': array([     1,      4,      7, ..., 112896, 112899, 112902]), 'fixdofs': array([     0,      2,      3,      5,      6,      8,      9,     11,\n",
      "           12,     14,     15,     17,     18,     20,     21,     23,\n",
      "           24,     26,     27,     29,     30,     32,     33,     35,\n",
      "           36,     38,     39,     41,     42,     44,     45,     47,\n",
      "           48,     50,     51,     53,     54,     56,     57,     59,\n",
      "           60,     62,     63,     65,     66,     68,     69,     71,\n",
      "           72,     74,     75,     77,     78,     80,     81,     83,\n",
      "           84,     86,     87,     89,     90,     92,     93,     95,\n",
      "           96,     98,     99,    101,    102,    104,    105,    107,\n",
      "          108,    110,    111,    113,    114,    116,    117,    119,\n",
      "          120,    122,    123,    125,    126,    128,    129,    131,\n",
      "          132,    134,    135,    137,    138,    140,    141,    143,\n",
      "          144,    146,    147,    149,    150,    152,    153,    155,\n",
      "          156,    158,    159,    161,    162,    164,    165,    167,\n",
      "          168,    170,    171,    173,    174,    176,    177,    179,\n",
      "          180,    182,    183,    185,    186,    188,    189,    191,\n",
      "          192,    194,    195,    197,    198,    200,    201,    203,\n",
      "          204,    206,    207,    209,    210,    212,    213,    215,\n",
      "          216,    218,    219,    221,    222,    224,    225,    227,\n",
      "          228,    230,    231,    233,    234,    236,    237,    239,\n",
      "          240,    242,    243,    245,    246,    248,    249,    251,\n",
      "          252,    254,    255,    257,    258,    260,    261,    263,\n",
      "          264,    266,    267,    269,    270,    272,    273,    275,\n",
      "          276,    278,    279,    281,    282,    284,    285,    287,\n",
      "          288,    290,    291,    293,    294,    296,    297,    299,\n",
      "          300,    302,    303,    305,    306,    308,    309,    311,\n",
      "          312,    314,    315,    317,    318,    320,    321,    323,\n",
      "          324,    326,    327,    329,    330,    332,    333,    335,\n",
      "          336,    338,    339,    341,    342,    344,    345,    347,\n",
      "          348,    350,    351,    353,    354,    356,    357,    359,\n",
      "          360,    362,    363,    365,    366,    368,    369,    371,\n",
      "          372,    374,    375,    377,    378,    380,    381,    383,\n",
      "          384,    386,    387,    389,    390,    392,    393,    395,\n",
      "          396,    398,    399,    401,    402,    404,    405,    407,\n",
      "          408,    410,    411,    413,    414,    416,    417,    419,\n",
      "          420,    422,    423,    425,    426,    428,    429,    431,\n",
      "          432,    434,    435,    437,    438,    440,    441,    443,\n",
      "          444,    446,    447,    449,    450,    452,    453,    455,\n",
      "          456,    458,    459,    461,    462,    464,    465,    467,\n",
      "          468,    470,    471,    473,    474,    476,    477,    479,\n",
      "          480,    482,    483,    485,    486,    488,    489,    491,\n",
      "          492,    494,    495,    497,    498,    500,    501,    503,\n",
      "          504,    506,    507,    509,    510,    512,    513,    515,\n",
      "          516,    518,    519,    521,    522,    524,    525,    527,\n",
      "          528,    530,    531,    533,    534,    536,    537,    539,\n",
      "          540,    542,    543,    545,    546,    548,    549,    551,\n",
      "          552,    554,    555,    557,    558,    560,    561,    563,\n",
      "          564,    566,    567,    569,    570,    572,    573,    575,\n",
      "          576,    578,    579,    581,    582,    584, 112897, 112898,\n",
      "       112900, 112901, 112903, 112904]), 'forces': array([ 0., -1.,  0., ...,  0.,  0.,  0.]), 'penal': 3.0, 'filter_width': 2}\n",
      "nelz: 2 nely: 64 nelx: 192\n",
      "total_resize: 8 , d: 0 , h: 8 , w: 24\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attr 'num_split' of 'Split' Op passed 0 less than minimum 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6dd3c232efa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpSampling3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m     return backend.resize_volumes(\n\u001b[0;32m-> 2659\u001b[0;31m         inputs, self.size[0], self.size[1], self.size[2], self.data_format)\n\u001b[0m\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mresize_volumes\u001b[0;34m(x, depth_factor, height_factor, width_factor, data_format)\u001b[0m\n\u001b[1;32m   3033\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3034\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3035\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3036\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrepeat_elements\u001b[0;34m(x, rep, axis)\u001b[0m\n\u001b[1;32m   3071\u001b[0m     splits = array_ops.split(value=x,\n\u001b[1;32m   3072\u001b[0m                              \u001b[0mnum_or_size_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3073\u001b[0;31m                              axis=axis)\n\u001b[0m\u001b[1;32m   3074\u001b[0m     \u001b[0;31m# repeat each slice the given number of reps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     \u001b[0mx_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(value, num_or_size_splits, axis, num, name)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 (numbers.Integral, tensor_shape.Dimension)):\n\u001b[1;32m   2010\u001b[0m     return gen_array_ops.split(\n\u001b[0;32m-> 2011\u001b[0;31m         axis=axis, num_split=num_or_size_splits, value=value, name=name)\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize_splits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(axis, value, num_split, name)\u001b[0m\n\u001b[1;32m   9889\u001b[0m   \u001b[0mnum_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_split\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9890\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 9891\u001b[0;31m         \"Split\", split_dim=axis, value=value, num_split=num_split, name=name)\n\u001b[0m\u001b[1;32m   9892\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9893\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    678\u001b[0m             raise ValueError(\n\u001b[1;32m    679\u001b[0m                 \u001b[0;34m\"Attr '%s' of '%s' Op passed %d less than minimum %d.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                 (key, op_type_name, attr_value.i, attr_def.minimum))\n\u001b[0m\u001b[1;32m    681\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"list(int)\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_MakeInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attr 'num_split' of 'Split' Op passed 0 less than minimum 1."
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "from PIL import Image\n",
    "import time\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray\n",
    "import pandas as pd\n",
    "\n",
    "from neural_structural_optimization import pipeline_utils\n",
    "from neural_structural_optimization import problems\n",
    "from neural_structural_optimization import models\n",
    "from neural_structural_optimization import topo_api\n",
    "from neural_structural_optimization import train\n",
    "\n",
    "def global_normalization(inputs, epsilon=1e-6):\n",
    "  mean, variance = tf.nn.moments(inputs, axes=list(range(len(inputs.shape))))\n",
    "  net = inputs\n",
    "  net -= mean\n",
    "  net *= tf.math.rsqrt(variance + epsilon)\n",
    "  return net\n",
    "\n",
    "#UpSampling2D→UpSampling3D\t20201214 K.Taniguchi\n",
    "def UpSampling3D(factor):\n",
    "  return layers.UpSampling3D((factor, factor, factor),data_format='channels_last')\n",
    "\n",
    "#Conv2D→Conv3D\t20201214 K.Taniguchi\n",
    "def Conv3D(filters, kernel_size, **kwargs):\n",
    "  return layers.Conv3D(filters, kernel_size, padding='same', **kwargs)\n",
    "\n",
    "\n",
    "problem = problems.PROBLEMS_BY_NAME['mbb_beam_192x64x2_0.4']\n",
    "\n",
    "#print(problem)\n",
    "\n",
    "max_iterations = 100\n",
    "seed=0\n",
    "args=topo_api.specified_task(problem)\n",
    "latent_size=128\n",
    "dense_channels=32\n",
    "resizes=(1, 2, 2, 2, 1)\n",
    "conv_filters=(128, 64, 32, 16, 1)\n",
    "offset_scale=10\n",
    "kernel_size=(5, 5, 5)\n",
    "latent_scale=1.0\n",
    "dense_init_scale=1.0\n",
    "activation=tf.nn.tanh\n",
    "conv_initializer=tf.initializers.VarianceScaling\n",
    "normalization=global_normalization\n",
    "\n",
    "if len(resizes) != len(conv_filters):\n",
    "    raise ValueError('resizes and filters must be same size')\n",
    "\n",
    "activation = layers.Activation(activation)\n",
    "    \n",
    "print(\"args:\",args)\n",
    "\n",
    "total_resize = int(np.prod(resizes))\n",
    "d = args['nelz'] // total_resize\n",
    "h = args['nely'] // total_resize\n",
    "w = args['nelx'] // total_resize\n",
    "\n",
    "print(\"nelz:\",args['nelz'],\"nely:\",args['nely'],\"nelx:\",args['nelx'])\n",
    "print(\"total_resize:\",total_resize,\", d:\",d,\", h:\",h,\", w:\",w)\n",
    "\n",
    "net = inputs = layers.Input((latent_size,), batch_size=1)\n",
    "filters = d * h * w * dense_channels\n",
    "dense_initializer = tf.initializers.orthogonal(dense_init_scale * np.sqrt(max(filters / latent_size, 1)))\n",
    "net = layers.Dense(filters, kernel_initializer=dense_initializer)(net)\n",
    "net = layers.Reshape([d, h, w, dense_channels])(net)\n",
    "\n",
    "for resize, filters in zip(resizes, conv_filters):\n",
    "    net = activation(net)\n",
    "    net = UpSampling3D(resize)(net)\n",
    "    net = normalization(net)\n",
    "    net = Conv3D(filters, kernel_size, kernel_initializer=conv_initializer)(net)\n",
    "\n",
    "if offset_scale != 0:\n",
    "    net = AddOffset(offset_scale)(net)\n",
    "\n",
    "outputs = tf.squeeze(net, axis=[-1])\n",
    "\n",
    "self.core_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "latent_initializer = tf.initializers.RandomNormal(stddev=latent_scale)\n",
    "self.z = self.add_weight(shape=inputs.shape, initializer=latent_initializer, name='z')\n",
    "\n",
    "def call(self, inputs=None):\n",
    "    return self.core_model(self.z)\n",
    "    \n",
    "\n",
    "ds_cnn = train.train_lbfgs(model, max_iterations)\n",
    "dims = pd.Index(['cnn-lbfgs'], name='model')\n",
    "return xarray.concat([ds_cnn], dim=dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.7.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
