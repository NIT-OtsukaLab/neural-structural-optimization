{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 5)\n",
      "[[[1.6 1.6 1.6 1.6 1.6]\n",
      "  [1.6 1.6 1.6 1.6 1.6]]\n",
      "\n",
      " [[1.6 1.6 1.6 1.6 1.6]\n",
      "  [1.6 1.6 1.6 1.6 1.6]]]\n",
      "<tf.Variable 'Variable:0' shape=(2, 2, 5) dtype=float64, numpy=\n",
      "array([[[1.6, 1.6, 1.6, 1.6, 1.6],\n",
      "        [1.6, 1.6, 1.6, 1.6, 1.6]],\n",
      "\n",
      "       [[1.6, 1.6, 1.6, 1.6, 1.6],\n",
      "        [1.6, 1.6, 1.6, 1.6, 1.6]]])>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"PixelModel.__init_\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "nelz = 2\n",
    "nely = 2\n",
    "nelx = 5\n",
    "volfrac = 0.4\n",
    "mask = 4\n",
    "\n",
    "shape = (nelz, nely, nelx)\n",
    "z_init = np.broadcast_to(volfrac*mask, shape)\n",
    "z = tf.Variable(z_init, trainable=True)\n",
    "\n",
    "print(shape)\n",
    "print(z_init)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem(normals=array([[[[1., 0., 1.],\n",
      "         [1., 0., 1.],\n",
      "         [1., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 1.],\n",
      "         [1., 0., 1.],\n",
      "         [1., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 1.],\n",
      "         [1., 0., 1.],\n",
      "         [1., 0., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 1.],\n",
      "         [1., 0., 1.],\n",
      "         [1., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 1.],\n",
      "         [1., 0., 1.],\n",
      "         [1., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 1.],\n",
      "         [1., 0., 1.],\n",
      "         [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "       [[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "       [[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "       [[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "       [[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 1.],\n",
      "         [0., 1., 1.],\n",
      "         [0., 1., 1.]]]]), forces=array([[[[ 0., -1.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0., -1.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "       [[[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "       [[[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "       [[[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "       [[[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.]]]]), density=0.4, mask=1, name='mbb_beam_192x64x2_0.4', width=192, height=64, depth=2, mirror_left=False, mirror_right=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"problems.py PROBLEMS_BY_CATEGORY/NAME\"\"\"\n",
    "from typing import Optional, Union\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "\n",
    "X, Y, Z = 0, 1, 2\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Problem:\n",
    "    normals: np.ndarray\n",
    "    forces: np.ndarray\n",
    "    density: float\n",
    "    mask: Union[np.ndarray, float] = 1\n",
    "    name: Optional[str] = None\n",
    "    width: int = dataclasses.field(init=False)\n",
    "    height: int = dataclasses.field(init=False)\n",
    "    depth: int = dataclasses.field(init=False)\t#2020-12-07 K.Taniguchi\n",
    "    mirror_left: bool = dataclasses.field(init=False)\n",
    "    mirror_right: bool = dataclasses.field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.width = self.normals.shape[0] - 1\n",
    "        self.height = self.normals.shape[1] - 1\n",
    "        self.depth = self.normals.shape[2] - 1\t#2020-12-07 K.Taniguchi\n",
    "\n",
    "        if self.normals.shape != (self.width + 1, self.height + 1, self.depth + 1, 3):\t#2020-12-07 K.Taniguchi\n",
    "            raise ValueError(f'normals has wrong shape: {self.normals.shape}')\n",
    "        if self.forces.shape != (self.width + 1, self.height + 1, self.depth + 1, 3):\t#2020-12-07 K.Taniguchi\n",
    "            raise ValueError(f'forces has wrong shape: {self.forces.shape}')\n",
    "        if (isinstance(self.mask, np.ndarray) and self.mask.shape != (self.height, self.width, self.depth)):\t#2020-12-07 K.Taniguchi\n",
    "            raise ValueError(f'mask has wrong shape: {self.mask.shape}')\n",
    "    \n",
    "#2020-12-07 K.Taniguchi\n",
    "        self.mirror_left = (\n",
    "            self.normals[0, :, :, X].all() and not self.normals[0, :, :, Y].all() and not self.normals[0, :, :, Z].all()\n",
    "        )\n",
    "        self.mirror_right = (\n",
    "            self.normals[-1, :, :, X].all() and not self.normals[-1, :, :, Y].all() and not self.normals[-1, :, :, Y].all()\n",
    "        )\n",
    "    \n",
    "def mbb_beam(width=60, height=20, depth=2, density=0.5):\n",
    "    \"\"\"Textbook beam example.\"\"\"\n",
    "    normals = np.zeros((width + 1, height + 1, depth + 1, 3))\n",
    "    normals[-1, -1, :, Y] = 1\n",
    "    normals[-1, -1, :, Z] = 1\n",
    "    normals[0, :, :, X] = 1\n",
    "    normals[0, :, :, Z] = 1\n",
    "        \n",
    "    forces = np.zeros((width + 1, height + 1, depth +1, 3))\n",
    "    forces[0, 0, :, Y] = -1\n",
    "    return Problem(normals, forces, density)\n",
    "\n",
    "def cantilever_beam_full(width=60, height=60, depth=1, density=0.5, force_position=0):\n",
    "    \"\"\"Cantilever supported everywhere on the left.\"\"\"\n",
    "    # https://link.springer.com/content/pdf/10.1007%2Fs00158-010-0557-z.pdf\n",
    "    normals = np.zeros((width + 1, height + 1, depth +1, 3))\n",
    "    normals[0, :, :, :] = 1\n",
    "\n",
    "    forces = np.zeros((width + 1, height + 1, depth + 1, 3))\n",
    "    forces[-1, round((1 - force_position)*height), round(depth/2), Y] = -1\n",
    "    return Problem(normals, forces, density)\n",
    "\n",
    "PROBLEMS_BY_CATEGORY = {\n",
    "    \"mbb_beam\":[\n",
    "        mbb_beam(96, 32, 1, density=0.5),\n",
    "        mbb_beam(192, 64, 2, density=0.4),\n",
    "        mbb_beam(384, 128, 1, density=0.3),\n",
    "        mbb_beam(192, 32, 1, density=0.5),\n",
    "        mbb_beam(384, 64, 1, density=0.4),\n",
    "        mbb_beam(3, 3, 1, density=0.4)\n",
    "    ],\n",
    "    \"cantilever_beam_full\":[\n",
    "        cantilever_beam_full(96, 32, 1, density=0.4),\n",
    "        cantilever_beam_full(192, 64, 1, density=0.3),\n",
    "        cantilever_beam_full(384, 128, 1, density=0.2),\n",
    "        cantilever_beam_full(384, 128, 1, density=0.15),\n",
    "    ],\n",
    "}\n",
    "\n",
    "PROBLEMS_BY_NAME = {}\n",
    "for problem_class, problem_list in PROBLEMS_BY_CATEGORY.items():\n",
    "    for problem in problem_list:\n",
    "        name = f'{problem_class}_{problem.width}x{problem.height}x{problem.depth}_{problem.density}'\n",
    "        problem.name = name\n",
    "        assert name not in PROBLEMS_BY_NAME, f'redundant name {name}'\n",
    "        PROBLEMS_BY_NAME[name] = problem\n",
    "\n",
    "problem = PROBLEMS_BY_NAME['mbb_beam_192x64x2_0.4']\n",
    "max_iterations = 100\n",
    "#problem = PROBLEMS_BY_NAME['mbb_beam_3x3x1_0.4']\n",
    "\n",
    "print(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alldofs =  [     0      1      2 ... 112902 112903 112904]\n",
      "fixdofs =  [     0      2      3      5      6      8      9     11     12     14\n",
      "     15     17     18     20     21     23     24     26     27     29\n",
      "     30     32     33     35     36     38     39     41     42     44\n",
      "     45     47     48     50     51     53     54     56     57     59\n",
      "     60     62     63     65     66     68     69     71     72     74\n",
      "     75     77     78     80     81     83     84     86     87     89\n",
      "     90     92     93     95     96     98     99    101    102    104\n",
      "    105    107    108    110    111    113    114    116    117    119\n",
      "    120    122    123    125    126    128    129    131    132    134\n",
      "    135    137    138    140    141    143    144    146    147    149\n",
      "    150    152    153    155    156    158    159    161    162    164\n",
      "    165    167    168    170    171    173    174    176    177    179\n",
      "    180    182    183    185    186    188    189    191    192    194\n",
      "    195    197    198    200    201    203    204    206    207    209\n",
      "    210    212    213    215    216    218    219    221    222    224\n",
      "    225    227    228    230    231    233    234    236    237    239\n",
      "    240    242    243    245    246    248    249    251    252    254\n",
      "    255    257    258    260    261    263    264    266    267    269\n",
      "    270    272    273    275    276    278    279    281    282    284\n",
      "    285    287    288    290    291    293    294    296    297    299\n",
      "    300    302    303    305    306    308    309    311    312    314\n",
      "    315    317    318    320    321    323    324    326    327    329\n",
      "    330    332    333    335    336    338    339    341    342    344\n",
      "    345    347    348    350    351    353    354    356    357    359\n",
      "    360    362    363    365    366    368    369    371    372    374\n",
      "    375    377    378    380    381    383    384    386    387    389\n",
      "    390    392    393    395    396    398    399    401    402    404\n",
      "    405    407    408    410    411    413    414    416    417    419\n",
      "    420    422    423    425    426    428    429    431    432    434\n",
      "    435    437    438    440    441    443    444    446    447    449\n",
      "    450    452    453    455    456    458    459    461    462    464\n",
      "    465    467    468    470    471    473    474    476    477    479\n",
      "    480    482    483    485    486    488    489    491    492    494\n",
      "    495    497    498    500    501    503    504    506    507    509\n",
      "    510    512    513    515    516    518    519    521    522    524\n",
      "    525    527    528    530    531    533    534    536    537    539\n",
      "    540    542    543    545    546    548    549    551    552    554\n",
      "    555    557    558    560    561    563    564    566    567    569\n",
      "    570    572    573    575    576    578    579    581    582    584\n",
      " 112897 112898 112900 112901 112903 112904]\n",
      "freedofs =  [     1      4      7 ... 112896 112899 112902]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"topo_api.py specified_task\"\"\"\n",
    "problem = PROBLEMS_BY_NAME['mbb_beam_192x64x2_0.4']\n",
    "#problem = PROBLEMS_BY_NAME['mbb_beam_3x3x1_0.4']\n",
    "\n",
    "def specified_task(problem):\n",
    "    \"\"\"Given a problem, return parameters for running a topology optimization.\"\"\"\n",
    "    fixdofs = np.flatnonzero(problem.normals.ravel())\n",
    "    alldofs = np.arange(3 * (problem.width + 1) * (problem.height + 1) * (problem.depth + 1))\n",
    "    freedofs = np.sort(list(set(alldofs) - set(fixdofs)))\n",
    "    \n",
    "    #print(problem.normals)\n",
    "    #print(problem.normals.ravel())\n",
    "    #print(\"problem name is \", problem.name)\n",
    "    print(\"alldofs = \", alldofs)\n",
    "    print(\"fixdofs = \", fixdofs)\n",
    "    print(\"freedofs = \", freedofs)\n",
    "    \n",
    "    params = {\n",
    "        # material properties\n",
    "        'young': 1,\n",
    "        'young_min': 1e-9,\n",
    "        'poisson': 0.3,\n",
    "        'g': 0,\n",
    "        # constraints\n",
    "        'volfrac': problem.density,\n",
    "        'xmin': 0.001,\n",
    "        'xmax': 1.0,\n",
    "        # input parameters\n",
    "        'nelx': problem.width,\n",
    "        'nely': problem.height,\n",
    "        'nelz': problem.depth,\n",
    "        'mask': problem.mask,\n",
    "        'freedofs': freedofs,\n",
    "        'fixdofs': fixdofs,\n",
    "        'forces': problem.forces.ravel(),\n",
    "        'penal': 3.0,\n",
    "        'filter_width': 2,\n",
    "    }\n",
    "    return params\n",
    "\n",
    "args = specified_task(problem)\n",
    "\n",
    "#print(\"fixdofs =\", args['fixdofs'])\n",
    "#print(\"freedofs =\", args['freedofs'])\n",
    "#print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24576\n",
      "<neural_structural_optimization.topo_api.Environment object at 0x7fd2bb85b3c8>\n",
      "[<tf.Variable 'Variable:0' shape=(2, 64, 192) dtype=float64, numpy=\n",
      "array([[[0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        ...,\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4]],\n",
      "\n",
      "       [[0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        ...,\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4],\n",
      "        [0.4, 0.4, 0.4, ..., 0.4, 0.4, 0.4]]])>]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"models.py\"\"\"\n",
    "import autograd\n",
    "import autograd.core\n",
    "import autograd.numpy as np\n",
    "from neural_structural_optimization import topo_api\n",
    "import tensorflow as tf\n",
    "\n",
    "# requires tensorflow 2.0\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "\n",
    "def batched_topo_loss(params, envs):\n",
    "  losses = [env.objective(params[i], volume_contraint=True)\n",
    "            for i, env in enumerate(envs)]\n",
    "  return np.stack(losses)\n",
    "\n",
    "def convert_autograd_to_tensorflow(func):\n",
    "  @tf.custom_gradient\n",
    "  def wrapper(x):\n",
    "    vjp, ans = autograd.core.make_vjp(func, x.numpy())\n",
    "    return ans, vjp\n",
    "  return wrapper\n",
    "\n",
    "def set_random_seed(seed):\n",
    "  if seed is not None:\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, seed=None, args=None):\n",
    "    super().__init__()\n",
    "    set_random_seed(seed)\n",
    "    self.seed = seed\n",
    "    self.env = topo_api.Environment(args)\n",
    "\n",
    "  def loss(self, logits):\n",
    "    # for our neural network, we use float32, but we use float64 for the physics\n",
    "    # to avoid any chance of overflow.\n",
    "    # add 0.0 to work-around bug in grad of tf.cast on NumPy arrays\n",
    "    logits = 0.0 + tf.cast(logits, tf.float64)\n",
    "    f = lambda x: batched_topo_loss(x, [self.env])\n",
    "    losses = convert_autograd_to_tensorflow(f)(logits)\n",
    "    return tf.reduce_mean(losses)\n",
    "\n",
    "\n",
    "class PixelModel(Model):\n",
    "\n",
    "  def __init__(self, seed=None, args=None):\n",
    "    super().__init__(seed, args)\n",
    "    shape = (self.env.args['nelz'], self.env.args['nely'], self.env.args['nelx'])\n",
    "    z_init = np.broadcast_to(args['volfrac'] * args['mask'], shape)\n",
    "    self.z = tf.Variable(z_init, trainable=True)\n",
    "\n",
    "    print(z_init.size)\n",
    "    \n",
    "  def call(self, inputs=None):\n",
    "    return self.z\n",
    "\n",
    "\n",
    "def global_normalization(inputs, epsilon=1e-6):\n",
    "  mean, variance = tf.nn.moments(inputs, axes=list(range(len(inputs.shape))))\n",
    "  net = inputs\n",
    "  net -= mean\n",
    "  net *= tf.math.rsqrt(variance + epsilon)\n",
    "  return net\n",
    "\n",
    "\n",
    "def UpSampling2D(factor):\n",
    "  return layers.UpSampling2D((factor, factor), interpolation='bilinear')\n",
    "\n",
    "\n",
    "def Conv2D(filters, kernel_size, **kwargs):\n",
    "  return layers.Conv2D(filters, kernel_size, padding='same', **kwargs)\n",
    "\n",
    "\n",
    "class AddOffset(layers.Layer):\n",
    "\n",
    "  def __init__(self, scale=1):\n",
    "    super().__init__()\n",
    "    self.scale = scale\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.bias = self.add_weight(\n",
    "        shape=input_shape, initializer='zeros', trainable=True, name='bias')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.scale * self.bias\n",
    "\n",
    "\n",
    "class CNNModel(Model):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      seed=0,\n",
    "      args=None,\n",
    "      latent_size=128,\n",
    "      dense_channels=32,\n",
    "      resizes=(1, 2, 2, 2, 1),\n",
    "      conv_filters=(128, 64, 32, 16, 1),\n",
    "      offset_scale=10,\n",
    "      kernel_size=(5, 5),\n",
    "      latent_scale=1.0,\n",
    "      dense_init_scale=1.0,\n",
    "      activation=tf.nn.tanh,\n",
    "      conv_initializer=tf.initializers.VarianceScaling,\n",
    "      normalization=global_normalization,\n",
    "  ):\n",
    "    super().__init__(seed, args)\n",
    "\n",
    "    if len(resizes) != len(conv_filters):\n",
    "      raise ValueError('resizes and filters must be same size')\n",
    "\n",
    "    activation = layers.Activation(activation)\n",
    "\n",
    "    total_resize = int(np.prod(resizes))\n",
    "    h = self.env.args['nely'] // total_resize\n",
    "    w = self.env.args['nelx'] // total_resize\n",
    "\n",
    "    net = inputs = layers.Input((latent_size,), batch_size=1)\n",
    "    filters = h * w * dense_channels\n",
    "    dense_initializer = tf.initializers.orthogonal(\n",
    "        dense_init_scale * np.sqrt(max(filters / latent_size, 1)))\n",
    "    net = layers.Dense(filters, kernel_initializer=dense_initializer)(net)\n",
    "    net = layers.Reshape([h, w, dense_channels])(net)\n",
    "\n",
    "    for resize, filters in zip(resizes, conv_filters):\n",
    "      net = activation(net)\n",
    "      net = UpSampling2D(resize)(net)\n",
    "      net = normalization(net)\n",
    "      net = Conv2D(\n",
    "          filters, kernel_size, kernel_initializer=conv_initializer)(net)\n",
    "      if offset_scale != 0:\n",
    "        net = AddOffset(offset_scale)(net)\n",
    "\n",
    "    outputs = tf.squeeze(net, axis=[-1])\n",
    "\n",
    "    self.core_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    latent_initializer = tf.initializers.RandomNormal(stddev=latent_scale)\n",
    "    self.z = self.add_weight(\n",
    "        shape=inputs.shape, initializer=latent_initializer, name='z')\n",
    "\n",
    "  def call(self, inputs=None):\n",
    "    return self.core_model(self.z)\n",
    "\n",
    "\n",
    "model = PixelModel(args=args)\n",
    "print(model.env)\n",
    "print(model.trainable_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24576\n",
      "<__main__.PixelModel object at 0x7fd2bb8c7f98>\n",
      "<neural_structural_optimization.topo_api.Environment object at 0x7fd2bbfad6d8>\n",
      "[0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "[0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "[0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "24576\n",
      "[[[0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  ...\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]]\n",
      "\n",
      " [[0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  ...\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]\n",
      "  [0.4 0.4 0.4 ... 0.4 0.4 0.4]]]\n",
      "(2, 64, 192)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 24576 into shape (64,192)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-bc17cc3ef3be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inequality_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrap_autograd_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#非線形制約\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_maxeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#停止基準（関数評価の基準が設定数を超えたら停止）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#最適化実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mdesigns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume_contraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/nlopt/nlopt.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nlopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlast_optimize_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-bc17cc3ef3be>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x, grad)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"Returns a function that returns both value and gradient. Suitable for use\n\u001b[1;32m    134\u001b[0m     in scipy.optimize\"\"\"\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         raise TypeError(\"value_and_grad only applies to real scalar-output \"\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-bc17cc3ef3be>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume_contraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/taniguchi/reparam/neural_structural_optimization/topo_api.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(self, params, volume_contraint)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume_contraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     return topo_physics.objective(\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mvolume_contraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvolume_contraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     )\n",
      "\u001b[0;32m/users/taniguchi/reparam/neural_structural_optimization/topo_api.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nelz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nely'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nelx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume_contraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36mwrapped_reshape\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;31m# The reshape function doesn't support both ways, so we have to wrap it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reparam-cfaYz6qU/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 24576 into shape (64,192)"
     ]
    }
   ],
   "source": [
    "\"\"\"train.py def method_of_asymptotes\"\"\"\n",
    "import functools\n",
    "\n",
    "from absl import logging\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "from neural_structural_optimization import models\n",
    "from neural_structural_optimization import topo_physics\n",
    "import scipy.optimize\n",
    "import tensorflow as tf\n",
    "import xarray\n",
    "import numpy\n",
    "\n",
    "model = PixelModel(args=args)\n",
    "max_iterations = 100\n",
    "init_model = None\n",
    "\n",
    "def _get_variables(variables):\n",
    "    return np.concatenate([\n",
    "        v.numpy().ravel() if not isinstance(v, np.ndarray) else v.ravel()\n",
    "        for v in variables])\n",
    "\n",
    "import nlopt  # pylint: disable=g-import-not-at-top\n",
    "\n",
    "\"\"\"if not isinstance(model, models.PixelModel):\"\"\"\n",
    "if not isinstance(model, PixelModel):\n",
    "    raise ValueError('MMA only defined for pixel models')\n",
    "\n",
    "env = model.env\n",
    "\n",
    "if init_model is None:\n",
    "    x0 = _get_variables(model.trainable_variables).astype(np.float64)\n",
    "else:\n",
    "    x0 = constrained_logits(init_model).ravel()\n",
    "\n",
    "def objective(x):\n",
    "    return env.objective(x, volume_contraint=False)\n",
    "\n",
    "def constraint(x):\n",
    "    return env.constraint(x)\n",
    "\n",
    "def wrap_autograd_func(func, losses=None, frames=None):\n",
    "    def wrapper(x, grad):\n",
    "        if grad.size > 0:\n",
    "            value, grad[:] = autograd.value_and_grad(func)(x)\n",
    "        else:\n",
    "            value = func(x)\n",
    "        if losses is not None:\n",
    "            losses.append(value)\n",
    "        if frames is not None:\n",
    "            frames.append(env.reshape(x).copy())\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "print(model)\n",
    "print(model.env)\n",
    "print(_get_variables(model.trainable_variables))\n",
    "print(_get_variables(model.trainable_variables).astype(np.float64))\n",
    "print(x0)\n",
    "print(x0.size)\n",
    "print(x0.reshape(args['nelz'], args['nely'], args['nelx']))\n",
    "print(x0.reshape(args['nelz'], args['nely'], args['nelx']).shape)\n",
    "\n",
    "losses = []\n",
    "frames = []\n",
    "\n",
    "opt = nlopt.opt(nlopt.LD_MMA, x0.size)  #コンストラクタ\n",
    "opt.set_lower_bounds(0.0)  #下限制約\n",
    "opt.set_upper_bounds(1.0)  #上限制約\n",
    "opt.set_min_objective(wrap_autograd_func(objective, losses, frames))  #目的関数\n",
    "opt.add_inequality_constraint(wrap_autograd_func(constraint), 1e-8)  #非線形制約\n",
    "opt.set_maxeval(max_iterations + 1)  #停止基準（関数評価の基準が設定数を超えたら停止）\n",
    "opt.optimize(x0)  #最適化実行\n",
    "\n",
    "designs = [env.render(x, volume_contraint=False) for x in frames]\n",
    "optimizer_result_dataset(np.array(losses), np.array(designs), save_intermediate_designs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.7.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
